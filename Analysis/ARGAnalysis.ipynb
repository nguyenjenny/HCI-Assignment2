{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGAnalysis:\n",
    "\n",
    "    def __init__(self, directory):\n",
    "        # print('Make sure the directory has forward slashes')\n",
    "        import os\n",
    "        self.directory = directory\n",
    "        os.chdir(directory)\n",
    "        self.fileNameDF = self.FileNameDF()\n",
    "        self.eventDict = {'Sync': ('Filename timestamp sync', 1, ''),\n",
    "                          'BL1': ('Start pre movie pressed', 900, 'qc_ecg_noise_bl1'),\n",
    "                          'BubblesMod': ('Bubble Lab: Start positive modulation', 120, 'qc_ecg_noise_bubblesmod'),\n",
    "                          'JetpackMod': ('Jetpack Bootle: Start negative modulation', 120, 'qc_ecg_noise_jetpackmod'),\n",
    "                          'AstroMod': ('Astro Bootle: Start positive modulation', 120, 'qc_ecg_noise_astromod'),\n",
    "                          'KartMod': ('Bootle Kart: Start negative modulation', 120, 'qc_ecg_noise_kartmod'),\n",
    "                          'WizardMod': (\"Wizard's Adventure: Start positive modulation\", 120, 'qc_ecg_noise_wizardmod'),\n",
    "                          'BubblesPre': ('Bubble Lab: Game time started', 30, 'qc_ecg_noise_bubblespre'),\n",
    "                          'JetpackPre': ('Jetpack Bootle: Game time started', 30, 'qc_ecg_noise_jetpackpre'),\n",
    "                          'AstroPre': ('Astro Bootle: Game time started', 30, 'qc_ecg_noise_astropre'),\n",
    "                          'KartPre': ('Bootle Kart: Game time started', 30, 'qc_ecg_noise_kartpre'),\n",
    "                          'WizardPre': (\"Wizard's Adventure: Game time started\", 30, 'qc_ecg_noise_wizardpre'),\n",
    "                          'BubblesPost': ('Bubble Lab: Stop positive modulation', 30, 'qc_ecg_noise_bubblespost'),\n",
    "                          'JetpackPost': ('Jetpack Bootle: Stop negative modulation', 30, 'qc_ecg_noise_jetpackpost'),\n",
    "                          'AstroPost': ('Atro Bootle: Stop positive modulation', 30, 'qc_ecg_noise_astropost'),\n",
    "                          'KartPost': ('Bootle Kart: Start negative modulation', 30, 'qc_ecg_noise_kartpost'),\n",
    "                          'WizardPost': (\"Wizard's Adventure: Stop positive modulation\", 30, 'qc_ecg_noise_wizardpost'),\n",
    "                          'BL2': ('Start post movie pressed', 900, 'qc_ecg_noise_bl2')\n",
    "                          }\n",
    "        self.checkPickleAll()\n",
    "\n",
    "    def FileNameDF(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import glob\n",
    "        \"\"\" Using the folder structure of the participant data, getFileNameDF returns a data frame with the file names of the participant\n",
    "        Args:\n",
    "            directory (str): The string of the directory of the participant data\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame with the ID as index and all the file names\n",
    "\n",
    "        \"\"\"\n",
    "        self.fileNameDF = pd.DataFrame(columns=['ID'])\n",
    "        self.fileNameDF['ID'] = glob.glob('ARG_*')\n",
    "        columns = ['MainEvents.csv', 'UserData.xml', 'BlockShooterData.xml', 'JetPackData.xml', 'JumperData.xml',\n",
    "                   'RacerData.xml', 'WizardsData.xml']\n",
    "        for column in columns:\n",
    "            self.fileNameDF[column] = [glob.glob(i + '/*' + column)[0] for i in self.fileNameDF['ID']]\n",
    "        self.fileNameDF = self.fileNameDF.set_index('ID')\n",
    "        # fileNames.to_excel(\"FileNameOutput.xlsx\", sheet_name='FileName') #Uncomment to export table to excel\n",
    "        return self.fileNameDF\n",
    "\n",
    "    def getFileNames(self):\n",
    "        return self.fileNameDF\n",
    "\n",
    "    def getQuestionnaires(self, excel=\"False\"):\n",
    "        # TODO: Convert numberical columns into numbers\n",
    "        import pandas as pd\n",
    "        import xml.etree.ElementTree as ET\n",
    "        def getQuestionnaireData(questionnaire):\n",
    "            questionnaireDF = pd.DataFrame(columns=['{}_A{}'.format(questionnaire[:-4], i) for i in range(1, 4)])\n",
    "            for ID in self.fileNameDF.index:\n",
    "                xmlName = self.getFilePath(ID, questionnaire)\n",
    "                tree = ET.parse(xmlName)\n",
    "                root = tree.getroot()\n",
    "                questionnaireDF.loc[ID] = [tree.find(child.tag).text for child in root]\n",
    "                questionnaireDF.index.name = 'ID'\n",
    "            # if excel:\n",
    "            #    self.toExcel(questionnaireDF,\n",
    "            return questionnaireDF\n",
    "\n",
    "        columns = ['UserData.xml', 'BlockShooterData.xml', 'JetPackData.xml', 'JumperData.xml', 'RacerData.xml',\n",
    "                   'WizardsData.xml']\n",
    "        mergedDF = getQuestionnaireData(columns[0])\n",
    "        for column in columns[1:]:\n",
    "            newDF = getQuestionnaireData(column)\n",
    "            mergedDF = pd.merge(mergedDF, newDF, how='outer', left_index=True, right_index=True)\n",
    "        # mergedDF.to_excel(\"QuestionnaireDataOutput.xlsx\", sheet_name='QuestionnaireData') #Uncomment to export table to excel\n",
    "        return mergedDF\n",
    "\n",
    "    def remove(self, l: 'list of IDs to skip'):\n",
    "        for ID in l:\n",
    "            if self.checkID(ID):\n",
    "                self.fileNameDF = self.fileNameDF.drop(ID)\n",
    "                print('The ID: {} is has been removed'.format(ID))\n",
    "\n",
    "    def getFilePath(self, ID, fileName):\n",
    "        return self.fileNameDF.loc[ID][fileName]\n",
    "\n",
    "    def getARGEventTime(self, ID, event):\n",
    "        import pandas as pd\n",
    "        filePath = self.getFilePath(ID, 'MainEvents.csv')\n",
    "        events = pd.read_csv(filePath)\n",
    "        events = events.set_index('Event')\n",
    "        if type(events.loc[event]) == pd.DataFrame and event == 'Filename timestamp sync':\n",
    "            return events.loc[event].iloc[0][0]  # gets first instance of event\n",
    "        elif type(events.loc[event]) == pd.DataFrame:\n",
    "            return events.loc[event].iloc[-1][0]  # gets last instance of event\n",
    "        else:\n",
    "            return events.loc[event][0]\n",
    "\n",
    "    def parsePhysio(self, ID):\n",
    "        import pandas as pd\n",
    "        if self.checkID(ID):  # check if ID requested is the in the file name table\n",
    "            physio = pd.read_csv('{}/{}.txt'.format(ID, ID), header=None, skiprows=8)\n",
    "            physio.columns = [\"Time\", \"ECG\", \"SYNC\", \"EDA\", 'TEMP', 'RESP']\n",
    "            return physio  # data frame with the physio signals\n",
    "\n",
    "    def picklePhysio(self, ID):\n",
    "        physio = self.parsePhysio(ID)\n",
    "        physio.to_pickle('{}/{}.pkl'.format(ID, ID))\n",
    "\n",
    "    def checkPickle(self, ID):\n",
    "        import glob\n",
    "        if len(glob.glob('{}/{}.pkl'.format(ID, ID))) != 1:\n",
    "            self.picklePhysio(ID)\n",
    "            print('Pickle for ID: {} created'.format(ID))\n",
    "\n",
    "    def checkPickleAll(self):\n",
    "        for ID in self.fileNameDF.index:\n",
    "            self.checkPickle(ID)\n",
    "\n",
    "    def checkID(self, ID, show=True):\n",
    "        if ID in self.fileNameDF.index:\n",
    "            return True\n",
    "        else:\n",
    "            if show:\n",
    "                print('The ID: {} is not in fileNameDF.'.format(ID))\n",
    "            return False\n",
    "\n",
    "    def checkEvent(self, event, show=True):\n",
    "        if event in self.eventDict.keys():\n",
    "            return True\n",
    "        else:\n",
    "            if show:\n",
    "                print('The Event: {} is not valid.'.format(event))\n",
    "            return False\n",
    "\n",
    "    def unpicklePhysio(self, ID):\n",
    "        import pandas as pd\n",
    "        self.checkPickle(ID)\n",
    "        if self.checkID(ID):\n",
    "            return pd.read_pickle('{}/{}.pkl'.format(ID, ID))\n",
    "\n",
    "    def plotECG(self, ID):\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        if self.checkID(ID):\n",
    "            physio = self.unpicklePhysio(ID)\n",
    "            fig = plt.figure()\n",
    "            plt.plot(physio['Time'], physio['ECG'])\n",
    "            fig.suptitle('{} ECG Raw'.format(ID))\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Amplitude')\n",
    "\n",
    "    def getOffset(self, ID, physio):\n",
    "        from scipy.signal import find_peaks\n",
    "        if self.checkID(ID):\n",
    "            peaks, _ = find_peaks(physio['SYNC'].values, height=1500)\n",
    "            physioSyncTime = physio['Time'][peaks[0]]\n",
    "            argSyncTime = self.getARGEventTime(ID,\n",
    "                                               'Filename timestamp sync')  # used filename sync instead of first sync on\n",
    "            return physioSyncTime - argSyncTime\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def getOffsetDF(self):\n",
    "        import pandas as pd\n",
    "        self.offsetDF = pd.DataFrame(self.fileNameDF.index)\n",
    "        self.offsetDF['Offset'] = [self.getOffset(ID) for ID in self.fileNameDF.index]\n",
    "        self.offsetDF = self.offsetDF.set_index('ID')\n",
    "        return self.offsetDF\n",
    "\n",
    "    def getARGEventTimesDF(self):\n",
    "        import pandas as pd\n",
    "        self.ARGEventTimesDF = pd.DataFrame(\n",
    "            self.fileNameDF.index)  # Makes a new DF table with ID from the file name table as column\n",
    "        for event in self.eventDict:  # goes through all the key names (e.g. Sync, BL1, BubbleMod etc..)\n",
    "            self.ARGEventTimesDF[event] = [self.getARGEventTime(i, self.eventDict[event][0]) for i in\n",
    "                                           self.ARGEventTimesDF['ID']]\n",
    "        self.ARGEventTimesDF = self.ARGEventTimesDF.set_index('ID')\n",
    "        return self.ARGEventTimesDF\n",
    "\n",
    "    def getOffsetEventTime(self, ID, event, physio):\n",
    "        # OffsetEventTime = ARGEventTime + Offset\n",
    "        ARGEventTime = self.getARGEventTime(ID, self.eventDict[event][0])\n",
    "        offset = self.getOffset(ID, physio)\n",
    "        return ARGEventTime + offset\n",
    "\n",
    "    def getOffsetEventTimesDF(self):\n",
    "        import pandas as pd\n",
    "        self.getOffsetDF();\n",
    "        self.getARGEventTimesDF()\n",
    "        self.offsetEventTimesDF = pd.merge(self.ARGEventTimesDF, self.offsetDF, how='outer', left_index=True,\n",
    "                                           right_index=True)\n",
    "        for col in self.offsetEventTimesDF:\n",
    "            if col != 'Offset':\n",
    "                self.offsetEventTimesDF[col] = self.offsetEventTimesDF[col] + self.offsetEventTimesDF['Offset']\n",
    "        self.offsetEventTimesDF = self.offsetEventTimesDF.drop(columns=['Offset'])\n",
    "        return self.offsetEventTimesDF\n",
    "\n",
    "    def getPhysioEventIndex(self, ID, event, physio, duration=0, getIndex=True):\n",
    "        import bisect\n",
    "        offsetEventTime = self.getOffsetEventTime(ID, event, physio) + duration\n",
    "        # physioEventTime = min(physio['Time'], key=lambda x:abs(x-offsetEventTime))\n",
    "        physioEventIndex = bisect.bisect_left(physio['Time'], offsetEventTime)\n",
    "        if getIndex:\n",
    "            return physioEventIndex\n",
    "        else:\n",
    "            return physio.iloc[physioEventIndex][\"Time\"]\n",
    "\n",
    "    def cutPhysio(self, ID, event):\n",
    "        self.physio = self.unpicklePhysio(ID)\n",
    "        start = self.getPhysioEventIndex(ID, event, self.physio)\n",
    "        end = self.getPhysioEventIndex(ID, event, self.physio, self.eventDict[event][1], True)\n",
    "        return self.physio.iloc[start:end]\n",
    "\n",
    "    def plotEvent(self, ID, event, signal='ECG'):\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib\n",
    "        # matplotlib.use('TkAgg')\n",
    "        plt.interactive(True)\n",
    "        if self.checkID(ID) and self.checkEvent(event):\n",
    "            fig = plt.figure()\n",
    "            physio = self.cutPhysio(ID, event)\n",
    "            plt.plot(physio['Time'], physio[signal])\n",
    "            fig.suptitle('{} {} during {}'.format(ID, signal, event))\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.show()\n",
    "\n",
    "    def processECG(self, ID, event):\n",
    "        from biosppy.signals import ecg\n",
    "        physio = self.cutPhysio(ID, event)\n",
    "        out = ecg.ecg(signal=physio['ECG'].values, sampling_rate=2024, show=False)\n",
    "        ecgDict = out.as_dict()\n",
    "        return ecgDict\n",
    "\n",
    "    def getHeartRate(self, ID, event):\n",
    "        import numpy as np\n",
    "        ecgDict = self.processECG(ID, event)\n",
    "        return ecgDict['heart_rate'].mean()\n",
    "\n",
    "    def getHeartRateDF(self):\n",
    "        self.heartRateDF = pd.DataFrame(self.fileNameDF.index)\n",
    "        for event in self.eventDict:  # goes through all the key names (e.g. Sync, BL1, BubbleMod etc..)\n",
    "            if event != 'Sync':\n",
    "                self.heartRateDF[event] = [self.getHeartRate(ID, event) for ID in self.heartRateDF['ID']]\n",
    "                print(event)\n",
    "        self.heartRateDF = self.heartRateDF.set_index('ID')\n",
    "        return self.heartRateDF\n",
    "\n",
    "    def getQC(self, filePath):  # from excel\n",
    "        import pandas as pd\n",
    "        self.qcTable = pd.read_csv(filePath, keep_default_na=True, dtype={'qc_ecg_noise_bl1': str,\n",
    "                                                                          'qc_ecg_noise_bubblesmod': str,\n",
    "                                                                          'qc_ecg_noise_jetpackmod': str,\n",
    "                                                                          'qc_ecg_noise_astromod': str,\n",
    "                                                                          'qc_ecg_noise_kartmod': str,\n",
    "                                                                          'qc_ecg_noise_wizardmod': str,\n",
    "                                                                          'qc_ecg_noise_bubblespre': str,\n",
    "                                                                          'qc_ecg_noise_jetpackpre': str,\n",
    "                                                                          'qc_ecg_noise_astropre': str,\n",
    "                                                                          'qc_ecg_noise_kartpre': str,\n",
    "                                                                          'qc_ecg_noise_wizardpre': str,\n",
    "                                                                          'qc_ecg_noise_bubblespost': str,\n",
    "                                                                          'qc_ecg_noise_jetpackpost': str,\n",
    "                                                                          'qc_ecg_noise_astropost': str,\n",
    "                                                                          'qc_ecg_noise_kartpost': str,\n",
    "                                                                          'qc_ecg_noise_wizardpost': str,\n",
    "                                                                          'qc_ecg_noise_bl2': str})\n",
    "        self.qcTable = self.qcTable.set_index(\"participant_id\")\n",
    "        for ID in self.qcTable.index.values:\n",
    "            if not self.checkID(ID, False):\n",
    "                self.qcTable = self.qcTable.drop(\n",
    "                    ID)  # remove all the participants that do not yet have physio data (i.e. not in fileNameDF)\n",
    "        return self.qcTable\n",
    "\n",
    "    def calcNoise(self, ID, event):\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            import numpy as np\n",
    "            noiseStr = self.qcTable.loc[ID][self.eventDict[event][2]]\n",
    "            if noiseStr == \"0\" or noiseStr == 0 or noiseStr == \"\":\n",
    "                return 0\n",
    "            elif pd.Series([noiseStr]).equals(pd.Series([np.NaN])):\n",
    "                return \"TBD\"\n",
    "            else:\n",
    "                noiseStr = noiseStr.replace(' ', '').strip(',')\n",
    "                noiseSplit = noiseStr.split(',')\n",
    "                totalNoise = 0\n",
    "                for interval in noiseSplit:\n",
    "                    if len(interval.split('-')) == 2:\n",
    "                        a, b = interval.split('-')\n",
    "                        totalNoise += float(b) - float(a)\n",
    "                return totalNoise\n",
    "        except:\n",
    "            return \"Error\"\n",
    "\n",
    "    def getQCDF(self, token):\n",
    "        import pandas as pd\n",
    "        self.getQCRedcap(token)\n",
    "        d = self.eventDict.copy()\n",
    "        del d[\"Sync\"]\n",
    "        self.qcDF = pd.DataFrame(columns=[event + \"Time\" for event in d] + [event + \"PercentNoise\" for event in d])\n",
    "        for ID in self.qcTable.index.values:\n",
    "            self.qcDF.loc[ID] = [self.calcNoise(ID, event) for event in d] + [self.percentNoise(ID, event) for event in\n",
    "                                                                              d]\n",
    "        # self.qcDF = self.qcDF.set_index('ID')\n",
    "        return self.qcDF\n",
    "\n",
    "    def testParticipant(self, ID):\n",
    "        d = self.eventDict.copy()\n",
    "        del d[\"Sync\"]\n",
    "        for event in d:\n",
    "            print(event)\n",
    "            print(self.calcNoise(ID, event))\n",
    "\n",
    "    def percentNoise(self, ID, event):\n",
    "        try:\n",
    "            noise = self.calcNoise(ID, event)\n",
    "            if noise == \"TBD\":\n",
    "                return \"TBD\"\n",
    "            else:\n",
    "                return noise / self.eventDict[event][1] * 100\n",
    "        except:\n",
    "            return \"Error\"\n",
    "\n",
    "    def getParticipantIDs(self):\n",
    "        return self.fileNameDF.index.values\n",
    "\n",
    "    def toExcel(self, table, directory, fileName):\n",
    "        import pandas as pd\n",
    "        table.to_excel(\"{}/{}.xlsx\".format(directory, fileName))\n",
    "\n",
    "    def getQCRedcap(self, token):\n",
    "        import requests\n",
    "        import pandas as pd\n",
    "        from io import StringIO\n",
    "        records = list(self.fileNameDF.index.values)\n",
    "        data = {\n",
    "            'token': token,\n",
    "            'content': 'record',\n",
    "            'format': 'csv',\n",
    "            'type': 'flat',\n",
    "            'forms[0]': 'qc_ecg',\n",
    "            'fields[0]': 'participant_id',\n",
    "            'rawOrLabel': 'raw',\n",
    "            'rawOrLabelHeaders': 'raw',\n",
    "            'exportCheckboxLabel': 'false',\n",
    "            'exportSurveyFields': 'false',\n",
    "            'exportDataAccessGroups': 'false',\n",
    "            'returnFormat': 'csv'\n",
    "        }\n",
    "        i = 0\n",
    "        for record in records:\n",
    "            data[\"records[{}]\".format(i)] = record\n",
    "            i += 1\n",
    "        r = requests.post('https://redcap.hollandbloorview.ca/api/', data)\n",
    "        self.qcTable = pd.read_csv(StringIO(r.text))\n",
    "        self.qcTable = self.qcTable.set_index('participant_id')\n",
    "\n",
    "        return self.qcTable\n",
    "\n",
    "# ARG = ARGAnalysis('Z:/ARG (CTO 1610)/Volunteer_Work')\n",
    "ARG = ARGAnalysis('/Users/jenny/Documents/Work/2019-HollandBloorviewRA/AzadehKushki/ARG/Sample Data')\n",
    "# ARG.toExcel(ARG.getQuestionnaires(), \"/Users/jenny/Desktop\", \"test.xlsx\")\n",
    "# ARG.plotEvent(\"ARG_002\", \"BL1\")\n",
    "# ARG.getQC('/Users/jenny/Downloads/ARGCTO1610_DATA_2019-08-28_0731.csv')\n",
    "\n",
    "#table = ARG.getQCDF('C0210B5BDD6B1E40D8C82F185BF2DCAE')\n",
    "#ARG.toExcel(table, \"/Users/jenny/Desktop\", \"test.xlsx\")\n",
    "\n",
    "\n",
    "#from ARGAnalysis import ARGAnalysis\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MainEvents.csv</th>\n",
       "      <th>UserData.xml</th>\n",
       "      <th>BlockShooterData.xml</th>\n",
       "      <th>JetPackData.xml</th>\n",
       "      <th>JumperData.xml</th>\n",
       "      <th>RacerData.xml</th>\n",
       "      <th>WizardsData.xml</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARG_999</th>\n",
       "      <td>ARG_999/20190711-094718-MainEvents.csv</td>\n",
       "      <td>ARG_999/201907110947-UserData.xml</td>\n",
       "      <td>ARG_999/201907111014-BlockShooterData.xml</td>\n",
       "      <td>ARG_999/201907111018-JetPackData.xml</td>\n",
       "      <td>ARG_999/201907111021-JumperData.xml</td>\n",
       "      <td>ARG_999/201907111025-RacerData.xml</td>\n",
       "      <td>ARG_999/201907111028-WizardsData.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARG_002</th>\n",
       "      <td>ARG_002/20190726-100624-MainEvents.csv</td>\n",
       "      <td>ARG_002/201907261008-UserData.xml</td>\n",
       "      <td>ARG_002/201907261039-BlockShooterData.xml</td>\n",
       "      <td>ARG_002/201907261043-JetPackData.xml</td>\n",
       "      <td>ARG_002/201907261046-JumperData.xml</td>\n",
       "      <td>ARG_002/201907261050-RacerData.xml</td>\n",
       "      <td>ARG_002/201907261053-WizardsData.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MainEvents.csv  \\\n",
       "ID                                                \n",
       "ARG_999  ARG_999/20190711-094718-MainEvents.csv   \n",
       "ARG_002  ARG_002/20190726-100624-MainEvents.csv   \n",
       "\n",
       "                              UserData.xml  \\\n",
       "ID                                           \n",
       "ARG_999  ARG_999/201907110947-UserData.xml   \n",
       "ARG_002  ARG_002/201907261008-UserData.xml   \n",
       "\n",
       "                              BlockShooterData.xml  \\\n",
       "ID                                                   \n",
       "ARG_999  ARG_999/201907111014-BlockShooterData.xml   \n",
       "ARG_002  ARG_002/201907261039-BlockShooterData.xml   \n",
       "\n",
       "                              JetPackData.xml  \\\n",
       "ID                                              \n",
       "ARG_999  ARG_999/201907111018-JetPackData.xml   \n",
       "ARG_002  ARG_002/201907261043-JetPackData.xml   \n",
       "\n",
       "                              JumperData.xml  \\\n",
       "ID                                             \n",
       "ARG_999  ARG_999/201907111021-JumperData.xml   \n",
       "ARG_002  ARG_002/201907261046-JumperData.xml   \n",
       "\n",
       "                              RacerData.xml  \\\n",
       "ID                                            \n",
       "ARG_999  ARG_999/201907111025-RacerData.xml   \n",
       "ARG_002  ARG_002/201907261050-RacerData.xml   \n",
       "\n",
       "                              WizardsData.xml  \n",
       "ID                                             \n",
       "ARG_999  ARG_999/201907111028-WizardsData.xml  \n",
       "ARG_002  ARG_002/201907261053-WizardsData.xml  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARG.getFileNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
